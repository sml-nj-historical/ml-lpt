\chapter{ML-Antlr}

%\section{Overview}

Parsers analyze the syntactic structure of an input string, and are usually specified with some variant of context-free grammars.  \antlr{} is a parser generator for Standard ML based on Terence Parr's variant of $LL(k)$ parsing.  The details of the parsing algorithm are given in the companion implementation notes; the practical restrictions on grammars are discussed in Section~\ref{sec:antlr-llk}.  A parser generated by \antlr{} is a functor; it requires a module with the {\tt LEXER} signature:
\begin{verbatim}
    signature LEXER = sig
      type strm
      type pos = StreamPos.pos
      val getPos : strm -> pos
    end
\end{verbatim}
Applying the parser functor will yield a module containing a {\tt parse} function:
\begin{verbatim}
    val parse : (strm -> ParserToks.token * strm) -> strm -> 
                result_ty option * strm * ParserToks.token Repair.repair list
\end{verbatim}
where {\tt result\_ty} is determined by the semantic actions for the parser.  The {\tt ParserToks} module is generated by \antlr{} (see Section~\ref{sec:antlr-gencode}) and the {\tt Repair} module is available in the {\tt ml-lpt} library (see chapter~\ref{ch:ml-lpt}). 

Notable features of \antlr{} include:
\begin{itemize}
 \item Extended BNF format, including Kleene-closure (*), positive closure (+), and optional (?) operators.
 \item Robust, automatic error repair.
 \item Selective backtracking.
 \item ``Inherited attributes'': information can flow downward as well as upward during a parse.
 \item Semantic predicates: a syntactic match can be qualified by a semantic condition.
 \item Grammar inheritence.
 \item Convenient default actions, especially for EBNF constructions.
 \item Convenient abbreviations for token names (\emph{e{.}g{.}}, {\tt "("} rather than {\tt LP})
\end{itemize}
The tool is invoked from the command-line as follows:
\begin{verbatim}
    ml-antlr file
\end{verbatim}
where {\tt file} is the name of the input \ulex{} specification.
The output file will be called {\tt file.sml}.

\section{Background definitions}

Before describing \antlr{}, we need some terminology.  A \emph{context-free grammar} (CFG) is a set of \emph{token} (or \emph{terminal}) symbols, a set of \emph{nonterminal} symbols, a set of \emph{productions}, and a start symbol $S$, which must be a nonterminal.  
The general term \emph{symbol} refers to both tokens and nonterminals.  A production relates a nonterminal $A$ to a string of symbols $\alpha$; we write this relation as $A \ra \alpha$.  Suppose $\alpha A \beta$ is a symbol string, and $A$ is a nonterminal symbol.  We write $\alpha A \beta \Ra \alpha \gamma \beta$ if $A \ra \gamma$ is a production; this is called a one-step derivation.  In general, a CFG generates a language, which is a set of token strings.  The strings included in this language are exactly those token string derived in one or more steps from the start symbol $S$.

A parser recognizes whether an input string is in the language generated by a given CFG, usually computing some value (such as a parse tree) while doing so.  The computations performed during a parse are called \emph{semantic actions}.

\section{Specification format}

A \antlr{} specification is a list of semicolon-terminated \emph{declarations}.  Each declaration is either a \emph{directive} or a \emph{nonterminal definition}.  Directives are used to alter global specification properties (such as the name of the functor that will be generated) or to define the tokens for the grammar.  The nonterminal definitions specify the grammar itself.  The top-level grammar for \antlr{} is given in Figure~\ref{fig:antlr-syntax}.

\begin{figure}
\Grammar{
\GFirstB{spec}
	{$($ declaration \T{;} $)^*$}

\GFirstB{declaration}
	{directive}
\GNextB
	{nonterminal}

\GFirstB{directive}
	{\kw{defs} code}
\GNextB
	{\kw{import} STRING}
\GNextB
	{\kw{keywords} symbol$^+$}
\GNextB
	{\kw{name} ID}
\GNextB
	{\kw{refcell} ID \T{:} monotype \T{:==} code}
\GNextB
	{\kw{start} ID}
\GNextB
	{\kw{tokens} \T{:} tokdef $($ \T{|} tokdef $)^*$}
	
\GFirstB{code}
	{ \T{(} $\dots$ \T{)} }

\GFirstB{tokdef}
	{datacon $($ \T{(} STRING \T{)} $)^?$}

\GFirstB{datacon}
	{ID}
\GNextB
	{ID \T{of} monotype}
\GFirstB{monotype}
	{{\rm standard SML syntax for monomorphic types}}

\GFirstB{symbol}
	{ID}
\GNextB
	{STRING}
}
\caption{The top-level \antlr{} grammar}\label{fig:antlr-syntax}
\end{figure}

There are a few lexical details of the specification format worth mentioning.  First, SML-style comments (\texttt{(* ... *)}) are treated as ignored whitespace anywhere they occur in the specification, \emph{except} in segments of code.  The \textit{ID} symbol used in the grammar stands for alpha-numeric-underscore identifiers, starting with an alpha character.  The \textit{code} symbol represents a segment of SML code, enclosed in parentheses.  Extra parentheses occuring within strings or comments in code need not be balanced.  The \textit{STRING} symbol represents a double-quoted string.  Escape codes may be used, so $\backslash$ is written as $\backslash\backslash$.

A complete example specification appears in Figure~\ref{fig:ex-antlr}.

\begin{figure}
\begin{verbatim}
%name CalcParse;

%tokens
  : KW_let  ("let")  | KW_in   ("in")
  | ID of string     | NUM of Int.int
  | EQ      ("=")    | PLUS    ("+")
  | TIMES   ("*")    | MINUS   ("-")
  | LP      ("(")    | RP      (")")
  ;
  
exp(env)
  : "let" ID "=" exp@(env) 
    "in" exp@(AtomMap.insert(env, Atom.atom ID, exp1))
      => ( exp2 )
  | addExp@(env)
  ;
  
addExp(env)
  : multExp@(env) ("+" multExp@(env))*
      => ( List.foldr op+ 0 multExp::SR )
  ;
  
multExp(env)
  : prefixExp@(env) ("*" prefixExp@(env))*
      => ( List.foldr op* 1 prefixExp::SR )
  ;
  
prefixExp(env)
  : atomicExp@(env)
  | "-" prefixExp@(env)
      => ( ~prefixExp )
  ;
  
atomicExp(env)
  : ID  
      => ( valOf(AtomMap.find (env, Atom.atom ID)) )
  | NUM
  | "(" exp@(env) ")"
  ;
\end{verbatim}
\caption{An example ml-antlr specification}
\end{figure}

\section{Directives}

\subsection{The \kw{defs} directive}

The \kw{defs} directive is used to include a segment of code in the generated parser:  
\begin{verbatim}
    %defs (
      fun helperFn x = (* ... *)
    );
\end{verbatim}
All definitions given will be in scope for the semantic actions (see Section~\ref{sec:antlr-actions}).

\subsection{The \kw{import} directive}

An \kw{import} directive can appear only once in a specification.  The string given in the directive should hold the path to a grammar file (recall that $\backslash$ characters must be escaped).  By default, all of the nonterminal defintions appearing in the specified file are included in the grammar.  The token definitions of the imported file are not used.  See Section~\ref{sec:antlr-inheritence} for details on changing or removing inherited nonterminals.

\subsection{The \kw{name} directive}

The name to use for the generated parser functor is specified using \kw{name}.  In addition to the functor, \antlr{} will generate a module to define the {\tt token} datatype; if the parser is named {\tt Example}, then this module will be called {\tt ExampleToks}.

%\subsection{The \kw{refcell} directive}

\subsection{The \kw{start} directive}

A particular nonterminal must be designated as the start symbol for the grammar.  The start symbol can be specified using \kw{start}; otherwise, the first nonterminal defined is assumed to be the start symbol.

\subsection{The \kw{tokens} directive}

The alphabet of the parser is defined using \kw{tokens}.  The syntax for this directive resembles a datatype declaration in SML, except that optional abbreviations for tokens may be defined.  For example:
\begin{verbatim}
    %tokens
      : KW_let  ("let")  | KW_in   ("in")
      | ID of string     | NUM of Int.int
      | EQ      ("=")    | PLUS    ("+")
      | LP      ("(")    | RP      (")")
      ;
\end{verbatim}
Within nonterminal definitions, tokens may be referenced either by their name or abbreviation; the latter must always be double-quoted.

\section{Nonterminal definitions}\label{sec:antlr-nt}

\begin{figure}
\Grammar{
\GFirstB{nonterminal}
	{ntdef}
\GNextB
	{\kw{extend} ntdef}
\GNextB
	{\kw{replace} ntdef}
\GNextB
	{\kw{drop} ID$^+$}
	
\GFirstB{ntdef}
	{ID formals$^?$ \T{:} prodlist}

\GFirstB{formals}
	{ \T{(} ID $($ \T{,} ID $)^*$ \T{)} }
	
\GFirstB{prodlist}
	{production $($ \T{|} production $)^*$}
	
\GFirstB{production}
	{\kw{try}$^?$ named-item$^*$ $($ \kw{where} code $)^?$ $($ \T{=>} code $)^?$ }
\GFirstB{named-item}
	{$($ ID \T{:} $)^?$ item}
\GFirstB{item}
	{prim-item \T{?}}
\GNextB
	{prim-item \T{+}}
\GNextB
	{prim-item \T{*}}
	
\GFirstB{prim-item}
	{symbol $($ \T{@} code $)^?$}
\GNextB
	{ \T{(} prodlist \T{)} }

\GFirstB{symbol}
	{ID}
\GNextB
	{STRING}
}
\caption{The \antlr{} grammar for nonterminal definitions}\label{fig:antlr-nt-syntax}
\end{figure}

The syntax of nontermal definitions is given in Figure~\ref{fig:antlr-nt-syntax}.  As an illustration of the grammar, consider the following example, which defines a nonterminal with three productions, taking a formal parameter {\tt env}:
\begin{verbatim}
    atomicExp(env)
      : ID => ( valOf(AtomMap.find (env, Atom.atom ID)) )
      | NUM
      | "(" exp@(env) ")"
      ;
\end{verbatim}
Note that actions are only allowed at the end of a production, and that they are optional.

\subsection{Extended BNF constructions}

In standard BNF syntax, the right side of a production is a simple string of symbols.  Extended BNF allows regular expression-like operators to be used: {\tt *}, {\tt +}, and {\tt ?} can follow a symbol, denoting 0 or more, 1 or more, or 0 or 1 occurrences respectively.  In addition, parentheses can be used within a production to enclose a \emph{subrule}, which may list several {\tt |}-separated alternatives, each of which may have its own action.  In the following example, the nonterminal {\tt item\_list} matches a semicolon-terminated list of identifiers and integers:
\begin{verbatim}
    item_list : (( ID | INT ) ";")* ;
\end{verbatim}
All of the extended BNF constructions have implications for the actions of a production; see Section~\ref{sec:antlr-actions} for details.

\subsection{Inherited attributes}

In most parsers, information can flow upward during the parse through actions, but not downard.  In attribute grammar terminology, the former refers to \emph{synthesized} attributes, while the latter refers to \emph{inherited attributes}.  Since \antlr{} is a predictive parser, it allows both kinds of attributes.  Inherited attributes are treated as parameters to nonterminals, which can be used in their actions or semantic predicates.  Formal parameters are introduced by enclosing them in parentheses after the name of a nonterminal and before its production list; the list of parameters will become a tuple.  In the following, the nonterminal {\tt expr} takes a single parameter called {\tt env}:
\begin{verbatim}
    expr(env) : (* ... *) ;
\end{verbatim}
If a nonterminal has a formal parameter, any use of that nonterminal is required to apply it to an actual parameter.  Actual parameters are introduced in a production by giving the name of a nonterminal, followed by the {\tt @} sign, followed by the code to compute the parameter.  For example:
\begin{verbatim}
    assignment : ID ":=" expr@(Env.emptyEnv) ;
\end{verbatim}

\subsection{Selective backtracking}

Sometimes it is inconvenient or impossible to construct a nonterminal definition which can be unambiguously resolved with finite lookahead.% (see Section~\ref{sec:antlr-llk} for examples).  
  The \kw{try} keyword can be used to mark ambiguous \emph{productions} for selective backtracking.  For backtracking to take place, each involved production must be so marked.  Consider the following:
\begin{verbatim}
    A : %try B* ";"
      | %try B* "(" C+ ")"
      ;
\end{verbatim}
As written, the two productions cannot be distinguished with finite lookahead, since they share an arbitrary long prefix of {\tt B} nonterminal symbols.  Adding the \kw{try} markers tells \antlr{} to attempt to parse the first alternative, and if that fails to try the second.  Another way to resolve the ambiguity is the use of subrules, which do not incur a performance penalty:
\begin{verbatim}
    A : B* ( ";"
           | "(" C+ ")"
           )
      ;
\end{verbatim}
This is essentially \emph{left-factoring}. See Section~\ref{sec:antlr-llk} for more guidance on working with the $LL(k)$ restriction.

\subsection{Semantic predicates}

A production can be qualified by a \emph{semantic predicate} by introducting a \kw{where} clause.  Even if the production is syntactically matched by the input, it will not be used unless its semantic predicate evaluates to {\tt true}.  A \kw{where} clause can thus introduce context-sensitivity into a grammar.  The following example uses an inherited {\tt env} attribute, containing a variable-value environment:
\begin{verbatim}
    atomicExp(env)
      : ID %where ( AtomMap.inDomain(env, Atom.atom ID) )
           => ( valOf(AtomMap.find (env, Atom.atom ID)) )
      | NUM
      | "(" exp@(env) ")"
      ;
\end{verbatim}
In this example, if a variable is mentioned that has not been defined, the error is detected and reported during the parse as a syntax error.

Semantic predicates are most powerful when combined with selective backtracking.  The combination allows two syntactically identical phrases to be distinguished by contextual, semantic information.

\subsection{Modifying inherited nonterminals}\label{sec:antlr-inheritence}

Nonterminal definitions imported using the \kw{import} directive can be altered in several ways.  In the simplest case, a nonterminal can be dropped entirely using the \kw{drop} keyword.  Alternatively, the productions of a definition can be replaced using \kw{replace}, or new productions can be added using \kw{extend}.  Note that these alterations may appear anywhere in the grammar; the order is irrelevant.  For each imported nonterminal, only one of \kw{drop}, \kw{replace}, or \kw{extend} may be used.  The resulting grammar must, of course, ensure that all used nonterminals are defined.

\subsection{Actions}\label{sec:antlr-actions}

Actions for productions are just SML code enclosed in parentheses.  In scope for the action are all the user definitions from the \kw{defs} directive.  In addition, the formal parameters of the production are in scope, as are the semantic yield of all symbols to the left of the action (the yield of a token is the data associated with that token's constructor).  In the following example, the first action has {\tt env} and {\tt exp} in scope, while the second action has {\tt env} and {\tt NUM} in scope:
\begin{verbatim}
    atomicExp(env)
      : "(" exp@(env) ")" => ( exp )
      | NUM => ( NUM )
      ;
\end{verbatim}
Notice also that the actual parameter to {\tt exp} in the first production is {\tt env}, which is in scope at the point the parameter is given; {\tt exp} itself would not be in scope at that point.

An important aspect of actions is naming: in the above example, {\tt exp} and {\tt NUM} were the default names given to the symbols in the production.  In general, the default name of a symbol is just the symbol's name.  If the same name appears multiple times in a production, a number is appended to the name of each yield, start from 1, going from left to right.  A subrule (any items enclosed in parentheses) is by default called {\tt SR}.  Any default name may be overriden using the syntax {\tt name=symbol}.  Overriding a default name does \emph{not} change the automatic number for other default names.  Consider:
\begin{verbatim}
    foo : A bar=A A ("," A)* A*
        ;
\end{verbatim}
In this production, the names in scope from left to right are: {\tt A1}, {\tt bar}, {\tt A3}, {\tt SR}, {\tt A4}.

The EBNF operators {\tt *}, {\tt +} and {\tt ?} have a special effect on the semantic yield of the symbols to which they are applied.  Both {\tt *} and {\tt +} yield a \emph{list} of the type of their symbol, while {\tt ?} yields an option.  For example, if {\tt ID*} appeared in a production, its default name would be {\tt ID}, and if the type of value of {\tt ID} was {\tt string}, it would yield a {\tt string list}; likewise {\tt ID?} would yield a {\tt string option}.  

Subrules can have embedded actions that determine their yield:
\begin{verbatim}
    plusList : ((exp "+" exp => ( exp1 + exp2 )) ";" => ( SR ))* => ( SR )
\end{verbatim}
The {\tt plusList} nonterminal matches a list of semicolon-terminated additions.  The innermost subrule, containing the addition, yields the value of the addition; that subrule is contained in a larger subrule terminated by a semicolon, which yield the value of the inner subrule.  Finally, the semicolon-terminated subrule is itself within a subrule, which is repeated zero or more times.  Note that the numbering scheme for names is restarted within each subrule.

Actions are \emph{optional}: if an action is not specified, the default behavior is to return all nonterminals and non-nullary tokens in scope.  Thus, the last example can be written as 
\begin{verbatim}
    plusList : ((exp "+" exp => ( exp1 + exp2 )) ";")*
\end{verbatim}
since {\tt "+"} and {\tt ";"} represent nullary token values.

\section{The $LL(k)$ restriction}\label{sec:antlr-llk}

When working with any parser, one must be aware of the restrictions is algorithm places on grammars.
When \antlr{} analyzes a grammar, it attempts to create a prediction-
decision tree for each nonterminal.  In the usual case, this decision
is made using lookahead token sets.  The tool will start with $k = 1$
lookahead and increment up to a set maximum until it can
uniquely predict each production.  Subtrees of the decision tree
remember the tokens chosen by their parents, and take this into account
when computing lookahead.  For example, suppose we have two productions
at the top level that generate the following sentences:
\begin{verbatim}
    prod1 ==> AA
    prod1 ==> AB
    prod1 ==> BC
    prod2 ==> AC
    prod2 ==> C
\end{verbatim}
At $k = 1$, the productions can generate the following sets:
\begin{verbatim}
    prod1 {A, B}
    prod2 {A, C}
\end{verbatim}
and $k = 2$,
\begin{verbatim}
    prod1 {A, B, C}
    prod2 {C, <EOF>}
\end{verbatim}
Examining the lookahead sets alone, this grammar fragment looks ambiguous
even for $k = 2$.  However, \antlr{} will generate the following decision
tree:
\begin{verbatim}
    if LA(0) = A then
      if LA(1) = A or LA(1) = B then
        predict prod1
      else if LA(1) = C then
        predict prod2
    else if LA(0) = B then
      predict prod1
    else if LA(1) = C then
      predict prod2
\end{verbatim}

In \antlr{}, only a small amount of lookahead is used by default ($k = 3$).  Thus, the following grammar is ambiguous for \antlr{}:
\begin{verbatim}
    foo : A A A B
        | A A A A
        ;
\end{verbatim}
and will generate the following error message:
\begin{verbatim}
    Error: lookahead computation failed for 'foo',
    with a conflict for the following productions:
      foo ::= A A A A EOF
      foo ::= A A A B EOF
    The conflicting token sets are:
      k = 1: {A}
      k = 2: {A}
      k = 3: {A}
\end{verbatim}
Whenever a lookahead ambiguity is detected, an error message of this form is given.  The listed productions are the point of conflict.  The {\tt k = ...} sets together give examples that can cause the ambiguity, in this case an input of {\tt AAA}.

The problem with this example is that the two {\tt foo} productions can only be distinguished by a token at $k = 4$ depth.  This situation can usually be resolved using \emph{left-factoring}, which lifts the common prefix of multiple productions into a single production, and then distinguishes the old productions through a subrule:
\begin{verbatim}
    foo : A A A (B | A)
        ;
\end{verbatim}
Recall that subrule alternatives can have their own actions:
\begin{verbatim}
    foo : A A A ( B => ( "got a B" ) 
                | A => ( "got an A" )
                )
        ;
\end{verbatim}
making left-factoring a fairly versatile technique.

Another limitation of predictive parsing is \emph{left-recursion}, where a nonterminal recurs without any intermediate symbols:
\begin{verbatim}
    foo : foo A A
        | B
        ;
\end{verbatim}
Left-recursion breaks predictive parsing, because it is impossible to make a prediction for a left-recursive production without already having a prediction in hand.  Usually, this is quite easily resolved using EBNF operators, since left-recursion is most often used for specifying lists.  Thus, the previous example can be rewritten as
\begin{verbatim}
    foo : B (A A)*
        ;
\end{verbatim}
which is both more readable and more amenable to $LL(k)$ parsing.

\section{Position tracking}

\antlr{} includes built-in support for propagating position information.  Because the lexer module is required to provide a {\tt getPos} function, the tokens themselves do not need to carry explicit position information.
A position \emph{span} is a pair to two lexer positions (the type {\tt StreamPos.span} is an abbreviation for {\tt StreamPos.pos * StreamPos.pos}).
Within action code, the position span of any symbol (token, nonterminal, subrule) is available as a value; if the yield of the symbol is named {\tt Sym}, its span is called {\tt Sym\_SPAN}.
Note that the span of a symbol after applying the {\tt *} or {\tt +} operators is the span of the entire matched list:
\begin{verbatim}
    foo : A* => (* A_SPAN starts at the first A and ends at the last *)
\end{verbatim}
In addition, the span of the entire current production is available as {\tt FULL\_SPAN}.

%\section{Handling precedence}

\section{Using the generated code}\label{sec:antlr-gencode}

The generated parser functor includes the following:
\begin{verbatim}
    val parse : (strm -> ParserToks.token * strm) -> strm -> 
                result_ty option * strm * ParserToks.token Repair.repair list
\end{verbatim}
where {\tt result\_ty} is the type of the semantic action for the grammar's start symbol.  
The parser is given a lexer function and a stream.
The result of a parse is the semantic yield of the parse, the value of the stream at the end of the parse, and a list of error repairs.  
If an unrepairable error occurred, {\tt NONE} is returned for the yield of the parse.

The {\tt Repair} module is part of the {\tt ml-lpt-lib} library; it is fully described in Chapter~\ref{ch:ml-lpt-lib}.  It includes a function {\tt repairToString}:
\begin{verbatim}
    val repairToString : StreamPos.sourcemap -> ('a list -> string) ->
                         'a repair -> string
\end{verbatim}
Likewise, the tokens module ({\tt ParserToks} in this example) includes a function {\tt toksToString}:
\begin{verbatim}
    val toksToString : token list -> string
\end{verbatim}
Thus, although error reporting is customizable, a reasonable default is provided, as illustrated below:
\begin{verbatim}
    let
      val sm = StreamPos.mkSourcemap()
      val (result, strm', errs) = Parser.parse (Lexer.lex sm) strm
      val errStrings = map (Repair.repairToString sm ParserToks.toksToString)
                           errs
    in
      print (concatWith "\n" errStrings)
    end
\end{verbatim}