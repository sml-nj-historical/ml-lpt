\chapter{Overview}\label{chap:overview}

In software, language recognition is ubiquitous: nearly every program deals at some level with structured input given in textual form.  The simplest recognition problems can be solved directly, but as the complexity of the language grows, recognition and processing become more difficult.  

Although sophisticated language processing is sometimes done by hand, the use of scanner and parser generators\footnote{
  ``Scanner generator'' and ``parser generator'' will often be shortened to ``scanner'' and ``parser'' respectively.  This is justified by viewing a parser generator as a parameterized parser.
} is more common.  The Unix tools {\tt lex} and {\tt yacc} are the archetypical examples of such generators.  Tradition has it that when a new programming language is introduced, new scanner and parser generators are written in that language, and generate code for that language.  Traditional \emph{also} has it that the new tools are modeled after the old {\tt lex} and {\tt yacc} tools, both in terms of the algorithms used, and often the syntax as well.  The language Standard ML is no exception: {\tt ml-lex} and {\tt ml-yacc} are the SML incarnations of the old Unix tools.

This manual describes two new tools, {\tt ml-ulex} and {\tt ml-antlr}, that follow tradition in separating scanning from parsing, but break from tradition in their implementation: {\tt ml-ulex} is based on \emph{regular expression derivatives} rather than subset-construction, and {\tt ml-antlr} is based on $LL(k)$ parsing rather than $LALR(1)$ parsing.   
%Importantly, the new implementations are by no means equivalent to the standard implementations

\section{Motivation}

Most parser generators use some variation of $LR$ parsing, a form of \emph{bottom-up} parsing that tracks possible interpretations of an input phrase until only a single interpretation is possible.  While this is a powerful technique, it has the following downsides:
\begin{itemize}
  \item 
\end{itemize} 

The main alternative to $LR$ parsing is the top-down, $LL$ approach, which is commonly used for hand-coded parsers.  An $LL$ parser, when faced with a decision point in the grammar, utilizes lookahead to unambiguously predict the correct interpretation of the input.  As a result, $LL$ parsers do not suffer from the problems above.  $LL$ parsers have been considered impractical because the size of their prediction table is exponential in $k$ --- the number of tokens to look ahead --- and many languages need $k > 1$.  However, Parr showed that an approximate form of lookahead, using tables linear in $k$, is usually sufficient.

%The primary motivation for this project is the new parser, {\tt ml-antlr}.  

\section{Outline}

This manual is organized into three parts: usage, theory, and implementation.  Each of these parts is further broken down into two chapters, one on {\tt ml-ulex} and one on {\tt ml-antlr}.  The usage section is self-contained, and gives a fairly complete specification of the two tools.  Full details on the algorithms used are given in the theory section.  Data structures, system organization, and other code-related particulars are described in the implementation section.




%Traditionally, sophisticated language recognition is performed in a two-phase process.  The first phase, \emph{lexical analysis}, separates the input text into tokens (or \emph{lexemes})

%Early on, 

%Traditionally, language recognition falls into two classes: \emph{scanning} (also called lexing), which can recognize regular languages, and \emph{parsers}

%Language recognition garnered much attention in the early days of computer science

%Two classes of languages---\emph{regular} and \emph{context-free}---emerged as having the most practical significance, in part because 

%; both the theory and practice of language recognition has long been considered settled.  

%, with \emph{regular} and \emph{context-free} languages emerging 

%The theory of language recognition has been extensively studied.  Of the classes of languages that have been studied, two in particular form the conceptual basis for most practical language recognition: the .